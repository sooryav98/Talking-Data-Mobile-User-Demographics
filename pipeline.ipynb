{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,Adagrad\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.callbacks import EarlyStopping,TensorBoard\n",
    "from statistics import mean\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatrain = pd.read_csv(\"data/gender_age_train.csv\",index_col='device_id')\n",
    "gatest = pd.read_csv(\"data/gender_age_test.csv\",index_col='device_id')\n",
    "phone=pd.read_csv(\"data/phone_brand_device_model.csv\")\n",
    "app_label=pd.read_csv('data/app_labels.csv')\n",
    "label_cat=pd.read_csv(\"data/label_categories.csv\")\n",
    "app_events=pd.read_csv(\"data/app_events.csv\", dtype={'is_active':bool})\n",
    "events = pd.read_csv('data/events.csv',  parse_dates=['timestamp'],index_col='event_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone = phone.drop_duplicates('device_id',keep='first').set_index('device_id') #removing duplicate device id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(gatrain,gatest,phone,app_label,label_cat,app_events,events,file):\n",
    "    start=datetime.now()\n",
    "    mask=np.in1d(gatrain.index,events[\"device_id\"].values)\n",
    "    gatrain_events= gatrain[mask]\n",
    "    mask=np.in1d(gatest.index,events[\"device_id\"].values)\n",
    "    gatest_events= gatest[mask]\n",
    "    mask=np.in1d(gatrain.index,events[\"device_id\"].values,invert=True)\n",
    "    gatrain_noevents= gatrain[mask]\n",
    "    mask=np.in1d(gatest.index,events[\"device_id\"].values,invert=True)\n",
    "    gatest_noevents= gatest[mask]\n",
    "\n",
    "    ##############################DATA Engineering##########################################\n",
    "    gatrain['trainrow'] = np.arange(gatrain.shape[0])\n",
    "    gatest['testrow'] = np.arange(gatest.shape[0])\n",
    "    gatrain_events['trainrow']=np.arange(gatrain_events.shape[0])\n",
    "    gatest_events['testrow']=np.arange(gatest_events.shape[0])\n",
    "    gatrain_noevents['trainrow']=np.arange(gatrain_noevents.shape[0])\n",
    "    gatest_noevents['testrow']=np.arange(gatest_noevents.shape[0])\n",
    "\n",
    "    brandencoder = LabelEncoder().fit(phone.phone_brand)\n",
    "    phone['brand'] = brandencoder.transform(phone['phone_brand'])\n",
    "    nbrand=len(brandencoder.classes_)\n",
    "    m = phone.phone_brand.str.cat(phone.device_model)\n",
    "    #m=phone['phone_brand'].str.cat(phone['device_model'])\n",
    "    modelencoder = LabelEncoder().fit(m)\n",
    "    phone['model'] = modelencoder.transform(m)\n",
    "    nmodel=len(modelencoder.classes_)\n",
    "\n",
    "    appencoder = LabelEncoder().fit(app_events['app_id'])\n",
    "    app_events['app'] = appencoder.transform(app_events['app_id'])\n",
    "    napps = len(appencoder.classes_)\n",
    "    deviceapps = (app_events.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n",
    "                           .groupby(['device_id','app'])['app'].agg(['size'])# grouping by device id and app and finding size of app\n",
    "                           .merge(gatrain_events[['trainrow']], how='left', left_index=True, right_index=True)#finding trainrow\n",
    "                           .merge(gatest_events[['testrow']], how='left', left_index=True, right_index=True)#finding testrow\n",
    "                           .reset_index())\n",
    "    app_label = app_label.loc[app_label.app_id.isin(app_events.app_id.unique())]\n",
    "    app_label['app'] = appencoder.transform(app_label.app_id)\n",
    "    labelencoder = LabelEncoder().fit(app_label.label_id)\n",
    "    app_label['label'] = labelencoder.transform(app_label.label_id)\n",
    "    nlabels = len(labelencoder.classes_)\n",
    "    devicelabels = (deviceapps[['device_id','app']]\n",
    "                    .merge(app_label[['app','label']])\n",
    "                    .groupby(['device_id','label'])['app'].agg(['size'])\n",
    "                    .merge(gatrain_events[['trainrow']], how='left', left_index=True, right_index=True)\n",
    "                    .merge(gatest_events[['testrow']], how='left', left_index=True, right_index=True)\n",
    "                    .reset_index())\n",
    "    events['hour'] = events['timestamp'].map(lambda x:pd.to_datetime(x).hour)\n",
    "    events['hourbin'] = [1 if ((x>=1)&(x<=6)) else 2 if ((x>=7)&(x<=12)) else 3 if ((x>=13)&(x<=18)) else 4 for x in events['hour']]\n",
    "    events.hour=events.hour.astype(str)\n",
    "    events.hourbin=events.hourbin.astype(str)\n",
    "    hourjoin = events.groupby(\"device_id\")[\"hour\"].apply(lambda x: \" \".join('0'+str(s) for s in x))\n",
    "    hourbinjoin=events.groupby(\"device_id\")[\"hourbin\"].apply(lambda x: \" \".join('0'+str(s) for s in x))\n",
    "    daysjoin=events['timestamp'].dt.day_name()\n",
    "    events['day']=daysjoin.map({'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6})\n",
    "    daysjoin = events.groupby(\"device_id\")[\"day\"].apply(lambda x: \" \".join(\"0\"+str(s) for s in x))\n",
    "    median_lat = events.groupby(\"device_id\")[\"latitude\"].agg('median')\n",
    "    median_lon=events.groupby(\"device_id\")[\"longitude\"].agg('median')\n",
    "    com=pd.concat([median_lat, median_lon], axis=1)\n",
    "    kmeans = KMeans(n_clusters=10, random_state=0).fit(com)\n",
    "    clustered_geo_features=pd.Series(kmeans.labels_)\n",
    "    clustered_geo_features.index=median_lon.index\n",
    "    apps = app_events.groupby(\"event_id\")[\"is_active\"].apply(lambda x: \" \".join(str(s) for s in x))\n",
    "    events[\"apps_active\"] = events.index.map(apps)\n",
    "    active_apps_events = events.groupby(\"device_id\")[\"apps_active\"].apply(lambda x: \" \".join(str(s) for s in x if str(s)!='nan'))\n",
    "    print(\"Data Preparation complete,time elapsed:\",datetime.now()-start)\n",
    "    ######################without_events###############################################\n",
    "    gatrain['model'] = phone['model']\n",
    "    gatest['model'] = phone['model']\n",
    "    Xtr_model = csr_matrix((np.ones(gatrain.shape[0]), \n",
    "                           (gatrain.trainrow, gatrain.model)))\n",
    "    Xte_model = csr_matrix((np.ones(gatest.shape[0]), \n",
    "                           (gatest.testrow, gatest.model)))\n",
    "    gatrain['brand'] = phone['brand']\n",
    "    gatest['brand'] = phone['brand']\n",
    "    Xtr_brand = csr_matrix((np.ones(gatrain.shape[0]), \n",
    "                           (gatrain.trainrow, gatrain.brand)))\n",
    "    Xte_brand = csr_matrix((np.ones(gatest.shape[0]), \n",
    "                           (gatest.testrow, gatest.brand)))\n",
    "    Xtrain_whole = hstack((Xtr_brand, Xtr_model), format='csr')\n",
    "    targetencoder = LabelEncoder().fit(gatrain.group)\n",
    "    y = targetencoder.transform(gatrain.group)\n",
    "    gatest_noevents['model']=phone['model']\n",
    "    gatest_noevents['brand']=phone['brand']\n",
    "    gatest_noevents_model = csr_matrix((np.ones(gatest_noevents.shape[0]), \n",
    "                           (gatest_noevents.testrow, gatest_noevents.model)))\n",
    "    gatest_noevents_brand= csr_matrix((np.ones(gatest_noevents.shape[0]), \n",
    "                           (gatest_noevents.testrow, gatest_noevents.brand)))\n",
    "    xtest_noevents=hstack((gatest_noevents_brand, gatest_noevents_model), format='csr')\n",
    "    model_list_1=[]\n",
    "    for i in range(5):\n",
    "        model=load_model('saved_models/noevents/nn'+str(i+1))\n",
    "        model_list_1.append(model)\n",
    "    avg_pred1=np.zeros((xtest_noevents.shape[0],12))\n",
    "    for i in range(len(model_list_1)):\n",
    "        test_pred=model_list_1[i].predict_proba(xtest_noevents)\n",
    "        avg_pred1+=test_pred\n",
    "    avg_pred1/=len(model_list_1)\n",
    "    print(\"Finished evaluating for  device id's without events,time elasped:\",datetime.now()-start)\n",
    "    ######################with_events###############################################\n",
    "    gatrain_events['brand']=phone['brand']\n",
    "    gatest_events['brand']=phone['brand']\n",
    "    Xtr_events_brand = csr_matrix((np.ones(gatrain_events.shape[0]), # Number of Rows/Devices\n",
    "                           (gatrain_events.trainrow, gatrain_events.brand)),shape=(gatrain_events.shape[0],nbrand))\n",
    "    Xte_events_brand = csr_matrix((np.ones(gatest_events.shape[0]), # Number of Rows/Devices\n",
    "                           (gatest_events.testrow, gatest_events.brand)),shape=(gatest_events.shape[0],nbrand))\n",
    "    gatrain_events['model']=phone['model']\n",
    "    gatest_events['model']=phone['model']\n",
    "    Xtr_events_model = csr_matrix((np.ones(gatrain_events.shape[0]), \n",
    "                           (gatrain_events.trainrow, gatrain_events.model)),shape=(gatrain_events.shape[0],nmodel))\n",
    "    Xte_events_model = csr_matrix((np.ones(gatest_events.shape[0]), \n",
    "                           (gatest_events.testrow, gatest_events.model)),shape=(gatest_events.shape[0],nmodel))\n",
    "    d = deviceapps.dropna(subset=['trainrow'])\n",
    "    Xtr_events_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n",
    "                          shape=(gatrain_events.shape[0],napps))\n",
    "    d = deviceapps.dropna(subset=['testrow'])\n",
    "    Xte_events_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n",
    "                          shape=(gatest_events.shape[0],napps))\n",
    "    d = devicelabels.dropna(subset=['trainrow'])\n",
    "    Xtr_events_labels = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n",
    "                          shape=(gatrain_events.shape[0],nlabels))\n",
    "    d = devicelabels.dropna(subset=['testrow'])\n",
    "    Xte_events_labels = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n",
    "                          shape=(gatest_events.shape[0],nlabels))\n",
    "    gatrain_events[\"hourjoin\"]=gatrain_events.index.map(hourjoin)\n",
    "    gatest_events[\"hourjoin\"]=gatest_events.index.map(hourjoin)\n",
    "    vectorizer=TfidfVectorizer()\n",
    "    vectorizer.fit(gatrain_events['hourjoin'].values)\n",
    "    X_tr_hourjoin_tfidf = vectorizer.transform(gatrain_events['hourjoin'].values)\n",
    "    X_te_hourjoin_tfidf = vectorizer.transform(gatest_events['hourjoin'].values)\n",
    "    gatrain_events[\"hourbinjoin\"]=gatrain_events.index.map(hourbinjoin)\n",
    "    gatest_events[\"hourbinjoin\"]=gatest_events.index.map(hourbinjoin)\n",
    "    vectorizer=CountVectorizer(binary=True)\n",
    "    vectorizer.fit(gatrain_events['hourbinjoin'].values)\n",
    "    X_tr_hourbinjoin_onehot = vectorizer.transform(gatrain_events['hourbinjoin'].values)\n",
    "    X_te_hourbinjoin_onehot = vectorizer.transform(gatest_events['hourbinjoin'].values)\n",
    "    gatrain_events[\"daysjoin\"]=gatrain_events.index.map(daysjoin)\n",
    "    gatest_events[\"daysjoin\"]=gatest_events.index.map(daysjoin)\n",
    "    vectorizer=TfidfVectorizer()\n",
    "    vectorizer.fit(gatrain_events['daysjoin'].values)\n",
    "    X_tr_daysjoin_tfidf = vectorizer.transform(gatrain_events['daysjoin'].values)\n",
    "    X_te_daysjoin_tfidf = vectorizer.transform(gatest_events['daysjoin'].values)\n",
    "    gatrain_events[\"latitude\"]=gatrain_events.index.map(median_lat)\n",
    "    gatest_events[\"latitude\"]=gatest_events.index.map(median_lat)\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(gatrain_events['latitude'].values.reshape(-1,1))\n",
    "    X_tr_event_lat = scaler.transform(gatrain_events['latitude'].values.reshape(-1,1))\n",
    "    X_te_event_lat = scaler.transform(gatest_events['latitude'].values.reshape(-1,1))\n",
    "    gatrain_events[\"longitude\"]=gatrain_events.index.map(median_lon)\n",
    "    gatest_events[\"longitude\"]=gatest_events.index.map(median_lon)\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(gatrain_events['longitude'].values.reshape(-1,1))\n",
    "    X_tr_event_lon = scaler.transform(gatrain_events['longitude'].values.reshape(-1,1))\n",
    "    X_te_event_lon = scaler.transform(gatest_events['longitude'].values.reshape(-1,1))\n",
    "    gatrain_events[\"locationbin\"]=gatrain_events.index.map(clustered_geo_features)\n",
    "    gatest_events[\"locationbin\"]=gatest_events.index.map(clustered_geo_features)\n",
    "    vectorizer= OneHotEncoder()\n",
    "    vectorizer.fit(gatrain_events['locationbin'].values.reshape(-1,1))\n",
    "    X_tr_clus = vectorizer.transform(gatrain_events['locationbin'].values.reshape(-1,1))\n",
    "    X_te_clus = vectorizer.transform(gatest_events['locationbin'].values.reshape(-1,1))\n",
    "    gatrain_events['apps_active']=gatrain_events.index.map(active_apps_events)\n",
    "    gatest_events['apps_active']=gatest_events.index.map(active_apps_events)\n",
    "    vectorizer=TfidfVectorizer()\n",
    "    vectorizer.fit(gatrain_events['apps_active'].values)\n",
    "    X_tr_active = vectorizer.transform(gatrain_events['apps_active'].values)\n",
    "    X_te_active = vectorizer.transform(gatest_events['apps_active'].values)\n",
    "    X_train_events=hstack((Xtr_events_brand,Xtr_events_model,Xtr_events_labels,X_tr_hourjoin_tfidf,X_tr_hourbinjoin_onehot,X_tr_daysjoin_tfidf,X_tr_event_lat,X_tr_event_lon,Xtr_events_app,X_tr_active,X_tr_clus),format='csr')\n",
    "    X_test_events =hstack((Xte_events_brand,Xte_events_model,Xte_events_labels,X_te_hourjoin_tfidf,X_te_hourbinjoin_onehot,X_te_daysjoin_tfidf,X_te_event_lat,X_te_event_lon,Xte_events_app,X_te_active,X_te_clus),format='csr')\n",
    "\n",
    "    model_list_1=[]\n",
    "    for i in range(5):\n",
    "        model=load_model('saved_models/events/nn1/nn1'+str(i+1))\n",
    "        model_list_1.append(model)\n",
    "    avg_pred2=np.zeros((X_test_events.shape[0],12))\n",
    "    for i in range(len(model_list_1)):\n",
    "        test_pred=model_list_1[i].predict_proba(X_test_events)\n",
    "        avg_pred2+=test_pred\n",
    "    avg_pred2/=len(model_list_1)\n",
    "\n",
    "    model_list_1=[]\n",
    "    for i in range(5):\n",
    "        model=load_model('saved_models/events/nn2/nn2'+str(i+1))\n",
    "        model_list_1.append(model)\n",
    "    avg_pred3=np.zeros((X_test_events.shape[0],12))\n",
    "    for i in range(len(model_list_1)):\n",
    "        test_pred=model_list_1[i].predict_proba(X_test_events)\n",
    "        avg_pred3+=test_pred\n",
    "    avg_pred3/=len(model_list_1)\n",
    "    print(\"Finished evaluating for  device id's with events,time elasped:\",datetime.now()-start)\n",
    "    ######################Ensemble###############################################\n",
    "    test1=(1*avg_pred1)\n",
    "    test2=(0.5*avg_pred2)+(0.5*avg_pred3)\n",
    "    gatrain=pd.read_csv('data/gender_age_train.csv',index_col = 'device_id')\n",
    "    targetencoder = LabelEncoder().fit(gatrain.group)\n",
    "    y = targetencoder.transform(gatrain.group)\n",
    "    nclasses = len(targetencoder.classes_)\n",
    "    pred_1 = pd.DataFrame(test1, index = gatest_noevents.index, columns=targetencoder.classes_)\n",
    "    pred_2 = pd.DataFrame(test2, index = gatest_events.index, columns=targetencoder.classes_)\n",
    "    final_pred=pd.concat([pred_1,pred_2], axis=0)\n",
    "    final_pred.to_csv(file,index=True)\n",
    "    print(\"Saved predictions file in\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation complete,time elapsed: 0:02:22.839516\n",
      "Finished evaluating for  device id's without events,time elasped: 0:03:22.465286\n",
      "Finished evaluating for  device id's with events,time elasped: 0:06:34.382918\n",
      "Saved predictions file inresults/final.csv\n"
     ]
    }
   ],
   "source": [
    "file='results/final.csv'\n",
    "pipeline(gatrain,gatest,phone,app_label,label_cat,app_events,events,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
